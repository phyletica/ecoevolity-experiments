\section{Introduction}

One of the primary goals of biodiversity research is to understand to what
degree the landscape, and changes to it, explain biological diversity within
and among species, and across communities.
A major component of this is understanding whether landscape-level processes
have driven diversification across multiple, independent evolutionary lineages.
Such processes are expected to generate patterns of divergence times that are
difficult to explain by lineage-specific processes of diversification.
Specifically, finding that divergence times are temporally clustered across
independent evolutionary lineages provides compelling evidence that a shared,
landscape-level process was responsible for the lineages diverging.
For example, the fragmentation of an environment, like an island, forest, or
watershed, can cause multiple taxa distributed across that environment to
co-diverge over a short interval relative to evolutionary timescales.
\thought{Better word than ``environment?'' I don't like landscape, because
    it excludes aquatic systems.}
% , such that a model that treats them as
% simultaneous will be a better explanation of the genetic variation than a model
% that treats the divergence of each lineage as independent \figureNeeded.
One way to test the predictions of such processes of diversification would be
to infer the temporal pattern of divergences within multiple taxa across an
environment, to determine whether any subsets of the taxa shared the same
divergence times.
% As a result, we stand to learn a lot about processes of diversification from
% a robust method for inferring the temporal pattern of divergences across
% multiple, independent lineages.
\thought{It would be nice to reference a cartoon example above}.

\begin{linenomath}
If we have pairs of populations for which we wish to infer and compare their
divergence times, we can approach this as a problem of model choice:
How many divergence events, and what assignment of taxa to those events, best
explain the genetic variation within and between the diverged populations of
each lineage (Figure~\ref{fig:divCarton})?
One challenge of this inference problem is the number of possible models.
If we have \ncomparisons pairs of populations, we would like to assign them to an
unknown number of divergence times, \nevents, which can range from one to
\ncomparisons.
For a given number of divergence times, the Stirling number of the second kind
tells us the number of ways of assigning the taxa to the divergence times
(i.e., the number of models with \nevents divergence-time parameters):
\begin{equation}
    S_2(\ncomparisons, \nevents) = 
    \frac{1}{\nevents!} \sum_{i = 0}^{\nevents - 1} (-1)^{i}
    \binom{\nevents}{i} (\nevents - i)^{\ncomparisons}.
    \label{eq:stirling2}
\end{equation}
When the number of divergence times is unknown, to get the total number of
possible divergence models, we need to sum over all possible values of
\nevents, which is Bell's number \citep{Bell1934}:
\begin{equation}
    B_{\ncomparisons} = \sum_{\nevents = 1}^{\ncomparisons}
    S_2(\ncomparisons, \nevents).
    \label{eq:bell}
\end{equation}
As the number of pairs we wish to compare grows, the prospect of comparing
maximum or marginal likelihoods among all possible models quickly becomes
daunting.
As a result, a Bayesian model-averaging approach is appealing, because it
allows the data to determine which models are most relevant.
\end{linenomath}

Methods have been developed to perform this model averaging using
approximate-likelihood Bayesian computation
\citep{Hickerson2006,Huang2011,Oaks2014dpp}.
However, these methods often struggle to detect multiple divergence times
across pairs of populations \citep{Oaks2012, Oaks2014reply} or have little
information to update \emph{a prior} expectations \citep{Oaks2014dpp}.
One proposed solution is to focus the inference problem on whether or not
\emph{all} the pairs diverged at the same time (i.e., $\nevents = 1$ versus
$\nevents > 1$)\citep{Hickerson2013}.
However, limiting the inference in this way is often not satisfactory, because
phylogeographers rarely expect that \emph{all} of the pairs of populations they
wish to compare diverged at the same time.
Limiting ourselves to the hypothesis of a single shared divergence would fail
to recognize situations where only a subset of taxa co-diverged, or where
multiple shared divergences have occurred.
The latter is particularly relevant when multiple landscape changes are known
to have occurred.
More fundamentally, Papadopoulou and Knowles \citeyear{Papadopoulou2016}
astutely pointed out that all of the pairs co-diverging is not the correct null
hypothesis.
If we wish to test for shared divergences, it is more appropriate to consider
all the pairs diverging independently as the null expectation.

Here, we introduce a new Bayesian model-choice method for inferring
shared divergence times across taxa.
Our method leverages recent analytical work \citep{Bryant2012} to efficiently
and directly compute the full-likelihood of divergence models from genomic
data.
By efficiently using all the information in the data, the new method is faster
and more accurate and precise than previous approximate-likelihood methods for
estimating shared divergences.
We will introduce the new method and its assumptions, assess its performance
with simulated data, and apply it to genomic data from geckos from the
Philippine Islands.


\section{Methods}

\subsection{The data}
We assume we have genetic data from multiple pairs of populations, and our goal
is to estimate the time that the two populations of each pair diverged, and
compare the divergence times among the pairs.
For each pair of populations that we wish to compare, we assume that we have
collected orthologous genetic markers with at most two states.
We will refer to these as ``biallelic characters,'' but note that this includes
constant characters.
We follow Bryant et al.\ \citeyear{Bryant2012} in referring to the two possible
states as ``red'' and ``green.''
We assume each character is effectivley unlinked, i.e., each marker evolved
along a gene tree that is independent of the others, conditional on the
population history.
Examples include well-spaced, single-nucleotide polymorhphisms (SNPs) or
amplified fragment-length polymorphisms (AFLPs).

For each population and for each marker we sample \allelecount
copies of the locus, \redallelecount of which are copies of the red
allele and the remaining $\allelecount - \redallelecount$ are
copies of the green allele;
\redallelecount can range from zero to \allelecount.
Thus, for each population of a pair, and for each locus, we have a count of the
total sampled copies of the locus and how many of those are the red allele.

We will use \leafallelecounts and \leafredallelecounts to denote allele counts
from both populations of a pair; i.e., 
$\leafallelecounts, \leafredallelecounts = (\allelecount[1], \redallelecount[1]), 
(\allelecount[2], \redallelecount[2])$.
We will use \comparisondata[i] to denote these counts for all the loci from
population pair $i$.
% and \alldata to represent the data across all the pairs of
% populations of which we wish to compare the divergence times.


\subsection{The model}

\subsubsection{The evolution of markers}

% We begin unpacking our model by first focusing on a single pair of populations.
We assume a finite-sites, continuous-time Markov chain (CTMC) model for the
evolution of the biallelic characters along a gene tree with branch lengths,
\genetree.
As the marker evolves along the gene tree, forward in time, there is a
instantaneous relative rate \rgmurate of mutating from the red state to the
green state, and a corresponding relative rate \grmurate of mutation from green
to red.
The stationary frequency of the red and green state is then
$\grmurate / (\rgmurate + \grmurate)$
and
$\rgmurate / (\rgmurate + \grmurate)$, respectively.
Thus, if given the frequency of the green allele, \gfreq, we can obtain the
relative rates of mutation between the two states.
We will denote the overall rate of mutation as \murate.
If $\murate = 1$, the gene tree branch lengths, and time in general, is in
units of expected mutations per site.
In such a case, for a given pair of populations, the \murate is a bit
redundant, because it can be incorporated into the branch lengths of the gene
tree.
However, we introduce the notation here, because it will be useful later if we
want to allow rate variation among pairs of populations.
If a mutation rate per site per unit time is given, then branch lengths are in
absolute time.
% For now, we will assume $\murate = 1$ so that the gene tree branch lengths, and
% time in general, is in units of the expected mutations per site.

\subsubsection{The evolution of gene trees}

We assume that each marker sampled from a pair of populations evolved within a
simple ``species'' tree with one ancestral root population that diverged into
two descendant (terminal) branches at time \comparisondivtime
(Figure~\ref{fig:divCarton}).
Again, if the $\murate$ is given, \comparisondivtime is absolute time, however,
if $\murate$ is set to one, time is in units of expected mutations per site.
We will use
$\comparisonpopsizes = \epopsize[\rootpopindex],
\epopsize[\descendantpopindex{1}], \epopsize[\descendantpopindex{2}]$
to denote
the effective sizes of the root and two descendant populations, respectively.
We will also use $\sptree = \comparisonpopsizes, \comparisondivtime$ as
shorthand for the species tree.

\subsubsection{The likelihood}

Given \murate, \gfreq, \comparisondivtime and \comparisonpopsizes, the
probability of the observed data at a marker (\allelecount and \redallelecount),
is the probability of the site pattern given a gene tree multiplied by the
probability of the gene given the species tree, summed over all possible gene
tree topologies and integrated over all possible gene tree branch lengths,
\begin{equation}
    \pr(\leafallelecounts, \leafredallelecounts \given \sptree, \murate, \gfreq)
    =
    \int_{\genetree}
    \pr(\leafallelecounts, \leafredallelecounts \given \genetree, \murate, \gfreq)
    \pr(\genetree, \murate, \gfreq \given \sptree)
    \diff{\genetree}
    \label{eq:markerlikelihood}
\end{equation}
\citep{Felsenstein1988,Nielsen2001,Rannala2003}.
We take advantage of the mathematical work of \citep{Bryant2012} to calculate
the integral over gene trees analytically, allowing us to compute the
likelihood of the species tree directly from the biallelic site patterns under
a coalescent model.
\thought{For completeness, should I lay out the math and algorithm for
    calculating the likelihood in the supplemental materials?}

Assuming independence among loci, conditional on the species tree, we can
calculate the probability of the \nloci loci given the specie trees by simply
taking the product over them,
\begin{equation}
    \pr(\comparisondata \given \sptree, \murate, \gfreq)
    =
    \prod_{i=1}^{\nloci}
    \pr(\leafallelecounts[i], \leafredallelecounts[i] \given \sptree, \murate, \gfreq).
    \label{eq:comparisonlikelihood}
\end{equation}
Finally, the likelihood across all of our pairs is simply the product of the
likelihood of each pair,
\begin{equation}
    \pr(
    \alldata
    \given
    \sptrees,
    \murates,
    \gfreqs)
    =
    \prod_{i=1}^{\ncomparisons}
    \pr(\comparisondata[i] \given \sptree[i], \murate[i], \gfreq[i]),
    \label{eq:collectionlikelihood}
\end{equation}
where
$\alldata = \comparisondata[1], \comparisondata[2], \ldots, \comparisondata[\ncomparisons]$,
$\sptrees = \sptree[1], \sptree[2], \ldots, \sptree[\ncomparisons]$,
$\murates = \murate[1], \murate[2], \ldots, \murate[\ncomparisons]$,
and
$\gfreqs = \gfreq[1], \gfreq[2], \ldots, \gfreq[\ncomparisons]$.


\subsubsection{Correcting for missing constant characters}

If we only sample variable characters, we need to correct the sample space for
the missing constant characters.
We can correct the likelihood by simply dividing by the probability of a
variable character, which is equal to one minus the probability of a constant
character,
\begin{equation}
\begin{split}
    \pr(\leafallelecounts, \leafredallelecounts \given \sptree, \murate, \gfreq, \textrm{variable})
    & =
    \frac{
        \pr(\leafallelecounts, \leafredallelecounts \given \sptree, \murate, \gfreq)
    }{
        \pr(\textrm{variable} \given \sptree, \murate, \gfreq)
    } \\
    & =
    \frac{
        \pr(\leafallelecounts, \leafredallelecounts \given \sptree, \murate, \gfreq)
    }{
        1 - \pr(\textrm{constant} \given \sptree, \murate, \gfreq)
    } \\
    & =
    \frac{
        \pr(\leafallelecounts, \leafredallelecounts \given \sptree, \murate, \gfreq)
    }{
        1 - \pr(\leafallelecounts \textrm{ all red} \given \sptree, \murate, \gfreq)
        - \pr(\leafallelecounts \textrm{ all green} \given \sptree, \murate, \gfreq)
    }.
    \label{eq:variablemarkerlikelihood}
\end{split}
\end{equation}
When we take the product over loci to get the probability of all the variable
data collected from a pair of populations, we correct each character pattern to
allow for different numbers of sampled gene copies among loci,
\begin{equation}
    \pr(\comparisondata \given \sptree, \murate, \gfreq, \textrm{variable})
    =
    \prod_{i=1}^{\nloci}
    \frac{
        \pr(\leafallelecounts[i], \leafredallelecounts[i] \given \sptree, \murate, \gfreq)
    }{
        1 - \pr(\leafallelecounts[i] \textrm{ all red} \given \sptree, \murate, \gfreq)
        - \pr(\leafallelecounts[i] \textrm{ all green} \given \sptree, \murate, \gfreq)
    }.
    \label{eq:variablecomparisonlikelihood}
\end{equation}
This is a bit different than the correction done in SNAPP.
If we use \maxleafallelecounts to denote the maximum number of gene copies
sampled from each population, then the correction in SNAPP is
\begin{equation}
    \pr_{\tiny SNAPP}(\comparisondata \given \sptree, \murate, \gfreq, \textrm{variable})
    =
    \frac{
        \prod_{i=1}^{\nloci}
        \pr(\leafallelecounts[i], \leafredallelecounts[i] \given \sptree, \murate, \gfreq).
    }{
        (1 - \pr(\maxleafallelecounts \textrm{ all red} \given \sptree, \murate, \gfreq)
        - \pr(\maxleafallelecounts \textrm{ all green} \given \sptree, \murate, \gfreq))^{\nloci}
    }.
    \label{eq:snappvariablecomparisonlikelihood}
\end{equation}
These are equivalent if the same number of samples are collected across all
loci for each population (i.e., no missing data), but will deviate if fewer
gene copies are sampled for at least one locus.
Thus, identical likelihoods between SNAPP and our method should not be expected
when analyzing variable-only data.

\subsection{Bayesian inference}

We can obtain a posterior probability distribution by naively plugging the
likelihood in Equation~\ref{eq:collectionlikelihood} into Baye's rule,
\begin{equation}
    \pr(
    \sptrees,
    \murates,
    \gfreqs
    \given
    \alldata
    )
    =
    \frac{
        \pr(
        \alldata
        \given
        \sptrees, \murates, \gfreqs
        )
        \pr(
        \sptrees,
        \murates,
        \gfreqs
        )
    }{
        \pr(
        \alldata
        )
    }.
    \label{eq:collectionindependentbayesrule}
\end{equation}
% By expanding out the species trees into their component parts, the divergence
% times and effective population sizes, we get
% \begin{equation}
%     \pr(
%     \comparisondivtimes,
%     \collectionpopsizes,
%     \murates,
%     \gfreqs
%     \given
%     \alldata
%     )
%     =
%     \frac{
%         \pr(
%         \alldata
%         \given
%         \comparisondivtimes,
%         \collectionpopsizes,
%         \murates,
%         \gfreqs
%         )
%         \pr(\comparisondivtimes, \collectionpopsizes, \murates, \gfreqs)
%     }{
%         \pr(
%         \alldata
%         )
%     }.
%     \label{eq:collectionindependentbayesruleexpanded}
% \end{equation}
However, this assumes all the species trees diverged independently, not
allowing us to learn about shared divergence times.
% this would be the same as calculating the posterior of each pair
% separately.
What we want to do is relax this assumption and allow pairs to share the same
divergence times.
% We want to estimate how many divergences occurred, and which pairs, if any,
% shared divergences.

Let's use \divtimemodel to represent the divergence model:
The divergence times, the number of which, \nevents, which can range from 1 to
\ncomparisons, and the mapping of non-overlapping subsets of the population
pairs to these \nevents divergence time.
We will separate out \divtimemodel into two components,
\begin{enumerate}
    \item the partitioning of the \ncomparisons population pairs to
        divergence events, which we will denote as \divtimesets, and
    \item the divergence times themselves,
        $\divtimes = \divtime[1], \ldots, \divtime[\nevents]$.
\end{enumerate}
We relax the assumption of independent divergence times by treating the number
of divergence events and the assignment of population pairs to those events as
random variables under a Dirichlet process prior \citep{Ferguson1973,
    Antoniak1974}.
Specifically, we use the Dirichlet process as a prior on divergence models,
$\divtimemodel \sim \dirp(\basedistribution, \concentration)$, where
\basedistribution is the base distribution of the process and \concentration is
concentration parameter that controls how clustered the process is.
The concentration parameter determines the prior probability of \divtimesets,
the partitioning of the population pairs, and the base distribution determines
the prior probability of the divergence time of each subset.

Under the Dirichlet process prior, the posterior becomes
\begin{equation}
    \pr(
    \concentration,
    \divtimemodel,
    \collectionpopsizes,
    \murates,
    \gfreq
    \given
    \alldata,
    \basedistribution
    )
    =
    \frac{
        \pr(
        \alldata
        \given
        \divtimemodel,
        \collectionpopsizes,
        \murates,
        \gfreqs
        )
        \pr(\divtimemodel \given \concentration, \basedistribution)
        \pr(\concentration)
        \pr(\collectionpopsizes)
        \pr(\murates)
        \pr(\gfreqs)
    }{
        \pr(
        \alldata,
        \basedistribution
        )
    }.
    \label{eq:bayesrule}
\end{equation}
By expanding out the divergence model (\divtimemodel) into the unique
divergence times (\divtimes) and the partitioning of the pairs of populations
to those times (\divtimesets), we get
\begin{equation}
    \pr(
    \concentration,
    \divtimes,
    \divtimesets,
    \collectionpopsizes,
    \murates,
    \gfreq
    \given
    \alldata,
    \basedistribution
    )
    =
    \frac{
        \pr(
        \alldata
        \given
        \divtimes,
        \divtimesets,
        \collectionpopsizes,
        \murates,
        \gfreqs
        )
        \pr(\divtimesets \given \concentration)
        \pr(\divtimes \given \divtimesets, \basedistribution)
        \pr(\concentration)
        \pr(\collectionpopsizes)
        \pr(\murates)
        \pr(\gfreqs)
    }{
        \pr(
        \alldata,
        \basedistribution
        )
    }.
    \label{eq:bayesruleexpanded}
\end{equation}

\subsubsection{Priors}

% \paragraph{Prior on divergence models}
% As mentioned above, we treat the number of divergence events and the assignment
% of population pairs to those events as random variables under a Dirichlet
% process prior \citep{Ferguson1973, Antoniak1974}.

\paragraph{Prior on concentration parameter}
Given a single parameter, \concentration, the Dirichlet process determines the
prior probability of all the possible ways the \ncomparisons pairs of
populations can be partitioned to \nevents = 1, 2, \ldots \ncomparisons
divergence events.
Given \concentration, the prior probability that two pairs of populations, $i$
and $j$ (assuming $i \neq j$), share the same divergence time is
\begin{equation}
    \pr(\comparisondivtime[i] = \comparisondivtime[j] \given \concentration)
    =
    \frac{1}{1 + \concentration}
\end{equation}
This illustrates that when the \concentration is small, the process tends to be
more clumped, and as it increases, the process tends to favor more independent
divergence times.
One option is to simply fix the concentration parameter to a particular value,
which is likely sufficient when the number of pairs is small.
Alternatively, we allow a hierarchical approach to accommodate uncertainty in
the concentration parameter by specifying a gamma distribution as a prior on
\concentration \citep{Escobar1995,Heath2011}.

\paragraph{Prior on divergence times}
Given the subsets of pairs assigned to divergence events, we use a gamma
distribution for the prior on the divergence time of each event,
$\divtime[i] \given \divtimesets \sim \distgamma(\cdot, \cdot)$.
This is the base distribution (\basedistribution) of the Dirichlet process.

\paragraph{Prior on effective population sizes}
For the two descendant populations of each pair, we use a gamma distribution as
the prior on the effective population size.
For the root population, we use a gamma distribution on the effective
population size \emph{relative} to the mean size of the two descendant
populations, which we denote as \rootrelativepopsize.
For example, a value of one would mean the root population size is equal to 
$(\epopsize[\descendantpopindex{1}] + \epopsize[\descendantpopindex{2}]) / 2$.
The goal of this approach is to allow more informative priors on the root
population size; we often have stronger prior expectations for the relative
effective size of the ancestral population than the absolute size.
This is important, because the effective size of the ancestral population is a
difficult nuisance parameter to estimate and is correlated with the divergence
time.
For example, if the divergence time is so old such that all the gene copies
of a locus coalesce within the descendant populations, the locus
provides very little information about the size of the ancestral
population.
As a result, a larger ancestral population and more recent divergence will have
a very similar likelihood to a small ancestral population and an older
divergence.
Thus, placing more prior density on reasonable values of the ancestral
population size can help improve the precision of divergence-time estimates.

\paragraph{Prior on mutation rates}
In the model presented above, for each population pair, the divergence time
(\divtime) and mutation rate (\murate) are inextricably linked.
For a single pair of populations, if little is known about the mutation rate,
this problem is easily sovlved by setting it to one ($\murate[1] = 1$) such
that time is in units of expected mutations per site and the effective
population sizes are scaled by \murate.
However, what about the second pair of populations for which we wish to compare
the divergence time to the first?
Because the species trees in our model are disconnected, we cannot learn about
the relative rates of mutation across the population pairs from the data.
As a result, we need strong prior information about the relative rates of
mutation across population pairs for this model to work.

If the second pair of populations is closely related to our first, and shares a
similar life history, we could assume they share the same mutation rate, and
set the mutation rate of the second pair to one as well ($\murate[2] = 1$).
Alternatively, we could relax that assumption and put a prior on \murate[2].
However, this should be a strongly informative prior.
Placing a very weakly informative prior on \murate[2] would mean that we can no
longer estimate its divergence time relative to the first pair.
So, while it is possible to incorporate uncertainty in relative mutation rates,
it is important to keep in mind that the data cannot inform these parameters,
and thus the uncertainty will be directly reflected in the uncertainty of
divergence times.

\paragraph{Prior on equilibrium state frequency}
Our method allows for a beta prior to be placed on the frequency of the green
allele for each pair of populations,
$\gfreq[i] \sim \textrm{Beta}(\cdot, \cdot)$.
However, if using SNP data, we advise fixing the frequency of the red and green
states to be equal (i.e., $\gfreq = 0.5$).
The reason for this is that there is no natural way of recoding four-state
nucleotides to two states, and so the relative transition rates, \rgmurate and
\grmurate, are not biologically meaningful.
There will always be arbitrariness associated with how one decides to perform
this re-coding, and unless $\gfreq = 0.5$, this arbitrariness will affect the
likelihood and results.
Constraining \gfreq to 0.5 makes the CTMC model a two-state analog of the
``JC69'' model \citep{JC1969}.
However, if the genetic markers are naturally biallelic, the frequencies of the
two states can be meaningfully estimated, making the model a two-state general
time-reversible model \citep{Tavare1986}.

\subsubsection{Approximating the posterior with MCMC}

We use Markov chain Monte Carlo (MCMC) algorithms to numerically approximate
the joint posterior in Equation~\ref{eq:bayesruleexpanded}.
We use the Gibbs sampling algorithm (Algorithm 8) of Neal \citeyear{Neal2000}
to update the divergence model (\divtimemodel) during the chain.
We also use univariate Metropolis-Hastings algorithms
\citep{Metropolis1953,Hastings1970} to update each parameter of the model
during the MCMC.
To improve mixing of the chain when there are strong correlations between
divergence times, mutation rates, and effective population size, we use
multivariate Metropolis-Hastings algorithms \ldots

\paragraph{`TimeRootSizeMixer' proposal}
One case of poor mixing can occur for pairs that diverge long enough ago such
that only a single coalescence occurs within the root for each locus.
In this scenario there is very little information in the allele count patterns
about the size of the ancestral population, and so the divergence time and root
size become highly correlated (i.e., an older divergence time and smaller root
size explain the data equally well as a younger divergence time and larger root
size).

For population pair $i$, we first draw a uniform random deviate, \uniformdeviate.
This and a tuning parameter \tuningparameter determines the value of a multiplier
\[
    \multiplier = e^{\tuningparameter(2\uniformdeviate - 1)}
\]
Next, we propose a new value for the effective population size of the
root population
\[
    \epopsize[\rootpopindex]{}\proposed = \multiplier\epopsize[\rootpopindex],
\]
and use \sizechange to denote the change in size,
\[
    \sizechange = \epopsize[\rootpopindex] - \multiplier\epopsize[\rootpopindex]
\]
Lastly, we propose a new value for the divergence time that population pair $i$
is currently mapped to,
\[
    \divtime\proposed = \divtime + 2\sizechange.
\]
Notice, for each value of \multiplier that proposes a change from
\epopsize[\rootpopindex] and \divtime to 
\epopsize[\rootpopindex]{}\proposed and \divtime\proposed,
there is exactly one corresponding value of \multiplier that
changes \emph{both}
\epopsize[\rootpopindex]{}\proposed and \divtime\proposed
back to 
\epopsize[\rootpopindex] and \divtime.
As a result, the probability of the proposed move and the corresponding move
that reverses it is determined by \multiplier.

The probability density of \multiplier, given \tuningparameter is
$1/(\tuningparameter\multiplier)$,
and the probability density of the proposal that would reverse the
move is $1/(\tuningparameter)$.
So, the ratio of the probability of reversing the proposed move and the
probability of the proposed move itself (Hastings ratio) is simply \multiplier.

This Metropolis-Hastings update is motivated by coalescent theory.
The expected time required for two lineages to coalesce within the
ancestral population is $2\epopsize[\rootpopindex]$.
The move proposes a \emph{change} in the expected time for the lineages to
coalesce in the ancestral population of
\[
    2\epopsize[\rootpopindex] - 2(\epopsize[\rootpopindex] - \sizechange) =
    2\epopsize[\rootpopindex] - 2\epopsize[\rootpopindex] - 2\sizechange =
    -2\sizechange.
\]
So, if we change the divergence time by $2\sizechange$, the root height of the
gene tree, and thus the probability of the data, will be the same before and
after the move.
This allows the update to jointly and efficiently explore the space of \divtime
and \epopsize[\rootpopindex] when there is little information in the data to
tease them apart.
However, note that the change to \divtime also changes the divergence times
of all the pairs that currently share this divergence time with pair $i$.
So, the efficiency of this move can be hindered when there is a lot of sharing
of divergence times.

\paragraph{`TimeSizeRateMixer' proposal}

For a given divergence time, \divtime[i], draw a multiplier as
\[
    \multiplier = e^{\tuningparameter(2\uniformdeviate - 1)},
\]
and propose a new value for \divtime[i],
\[
    \divtime[i]\proposed = \multiplier\divtime[i]
\]

\ldots

\subsection{Software implementation}
The method outlined above is implemented in the open-source software package,
\ecoevolity, written in the \cpp language.
The program is freely available from
\url{https://github.com/phyletica/ecoevolity}, and documentation is available
at
\url{http://phyletica.org/ecoevolity/}.


\subsection{Analyses of simulated data}

\subsubsection{Validation analyses}
Our first step to validate the new method was to verify that it behaves as
expected when the model is correct (i.e., data are simulated and analyzed under
the same model).
We used the \simcoevolity tool from the \ecoevolity package, which simulates
data under the same model used for inference that is described above.
All data were simulated under the following settings:
\begin{enumerate}
    \item $\ncomparisons = 3$
    \item $\concentration = 1.414216$, which corresponds with a prior mean of
        $\nevents = 2$ divergence events
    \item $\divtime \sim \dexponential{0.01}$
    \item $\gfreq = 0.5$
    \item $\murate = 1$
\end{enumerate}
We simulated data under five different settings for the effective population
sizes.
The first setting was an idealized situation where all population sizes were
known and equal,
$\epopsize[\rootpopindex] = 
\epopsize[\descendantpopindex{1}] =
\epopsize[\descendantpopindex{2}] = 0.002$.
The four remaining scenarios differed in their distribution on the relative
effective size of the root population:
\begin{enumerate}
    \item $\rootrelativepopsize \sim \dgamma{2}{1}$
    \item $\rootrelativepopsize \sim \dgamma{10}{1}$
    \item $\rootrelativepopsize \sim \dgamma{100}{1}$
    \item $\rootrelativepopsize \sim \dgamma{1000}{1}$
\end{enumerate}
For these four scenarios, the descendant populations were distributed as
\dgamma{5}{0.002}.
The most difficult nuisance parameter to estimate for a pair of populations is
the root population size, which can be correlated with the parameter of
interest, the divergence time.
Thus, our choice of simulation settings is designed to assess how uncertainty
in the root population size affects inference.

Under each of the five scenarios we simulated 500 data sets of 100,000
characters and 500 data sets of 500,000 characters.
This includes constant characters; the mean number of variable SNPs were
approximately 5,500 and 27,500, respectively.
We then analyzed all 5,000 simulated datasets in \ecoevolity both with and
without constant characters included.
For analyses where 
$\epopsize[\rootpopindex] = 
\epopsize[\descendantpopindex{1}] =
\epopsize[\descendantpopindex{2}] = 0.002$,
we ran
three independent MCMC chains for 37,500 generations, sampling every
25th generation.
For all other analyses, we ran the three chains for 75,000 generations,
sampling every 50th generation.
As a result we collected 4503 samples for each analysis (1501 samples from each
chain, including the initial state).

In order to assess the frequentist behavior of the posterior probabilities of
divergence models approximated by \ecoevolity, we simulated an additional
20,000 data sets of 100,000 characters under the setting where
$\rootrelativepopsize \sim \dgamma{100}{1}$.
All 20,500 data sets were analyzed with \ecoevolity and binned based on the
inferred posterior probability that $\nevents = 1$.
The mean posterior probability that $\nevents = 1$ for each bin was plotted
against the proportion of data sets within the bin for which the true
divergence model was $\nevents = 1$.
If the new method is unbiased, in a frequentist sense, the inferred posterior
probabilities that $\nevents = 1$ within a bin should approximately equal the
proportion of the data sets for which that is true
\citep{Huelsenbeck2004,Oaks2012,Oaks2014dpp}.

\subsubsection{Assessing effect of linkage violation}
The characters of most datasets being collected by high-throughput technologies
do not all evolve along independent gene trees.
Most consist of many putatively unlinked loci that each comprise sequences of
linked nucleotides.
For example, ``RADseq'' and ``sequence capture'' techniques generate thousands
of loci that are approximately 50--300 nucleotides in length.
This creates a question when using methods that assume each character is
independent:
Is it better to violate that assumption and use all the data, or throw
away much of the data to avoid the violation?

To better adhere to the independence assumption, we could retain only a single
site per locus.
This results in a very large loss of data.
Furthermore, to try and maximize the informativeness of the retained sites,
most researchers retain only one \emph{variable} character per locus.
While this can be corrected for (see
Equation~\ref{eq:variablecomparisonlikelihood}), it still results in the loss
of a very informative component of the data: The proportion of variable sites.
Before throwing away so much information, we should determine whether
it is in our best interest.
In other words, does keeping the data and violating the independence
assumption result in better or worse inferences than throwing out the 
data?

To address this question, 
we simulated datasets composed of loci of linked sites that were 100, 500, and
1000 characters long.
The characters for each locus were simulated along the same gene tree (i.e., no
intra-locus recombination).
Simulated datasets were analyzed with \ecoevolity in one of three ways:
(1) All characters were included,
(2) only variable characters were included,
and
(3) only a maximum of one variable character per locus was included.
Only the last option avoids violating the assumption of unlinked characters,
but throws out the most data.

For all three locus lengths, we simulated 500 data sets with a total of 100,000
and 500,000 characters.
The settings of the simulations performed with \simcoevolity, and subsequent
analyses with \ecoevolity, correspond with the validation analyses described
above where the relative size of the root population was distributed as
\dgamma{100}{1}.
Furthermore, to assess the affect of linked characters on the posterior
probabilities of divergence models, we simulated an additional 10,000 datasets
with 1,000, 100-character loci (100,000 total characters each).
As described above, to assess the frequentist behavior of approximated
posterior probabilities, we binned the results of the analyses of these 10,500
data sets based on the posterior probability that $\nevents = 1$.

\subsubsection{Assessing the effect of missing data}
Our method should be robust to missing data, because it is simply treated as a
smaller sample of gene copies from a particular population for a particular
locus.
This is because each character is assumed to have evolved along a coalescent
gene tree, the identity of each gene copy within a population does not matter.
Thus, some loci having fewer sampled gene copies from some populations should
result in more variance in parameter estimates, but is not expected to create
bias.
To confirm this behavior, we simulated datasets with different probabilities of
sampling each gene copy.
Specifically, we simulated datasets for which the probability of sampling each
gene copy was 90\%, 75\%, or 50\%, which resulted in datasets with
approximately 10\%, 25\%, or 50\% missing data.
For each sampling probability, we simulated 100 data sets with 500,000
characters; the settings were the same as described above where
$\rootrelativepopsize \sim \dgamma{100}{1}$.

\subsubsection{Assessing the effect of biases in character-pattern acquisition}
When analyzing the \spp{Gekko} data (see below), we observed large
discrepancies in the estimated divergence times depending on whether or not the
constant sites were removed from the analysis.
This was not observed in the analyses of simulated data, because the likelihood
is appropriately corrected for the missing constant sites.
This suggests that there is additional character-pattern acquisition biases in
the empirical data, which are not corrected for.
Such acquisition biases have been documented during the denovo assembly of
RADseq loci \citep{Harvey2015,Linck2017}.

The loss of rare alleles during the acquisition and assembly of the data could
explain the much larger divergence times estimated from the empirical data when
constant sites are removed.
After the constant sites, the rare alleles are ``next in line'' to inform the
model that the population divergence was recent.
If these patterns are being lost during data acquisition and assembly, and not
accounted for in the likelihood correction, this should create an upward bias
in the divergence time estimates.

To explore whether data acquisition bias can explain the discrepancy we
observed for the \spp{Gekko} data, we simulated datasets where the probability
of sampling singleton site patterns (i.e., one gene copy is different from all
the others) was 80\%, 60\%, and 40\%.
For each, we simulated 100 data sets for which the settings were
the same as described above where
$\rootrelativepopsize \sim \dgamma{100}{1}$.


\subsubsection{Comparison to ABC methods}
We wanted to compare the performance of the new method to the existing
approximate-likelihood Bayesian computation (ABC) method \dppmsbayes 
\citep{Oaks2014dpp}.
In order to do this, we had to simulate relatively small data sets that the ABC
methods could handle in a reasonable amount of time.
Accordingly, we simulated data sets with 200 loci, each with 200 linked
characters (40,000 total characters).
For analyses of both \ecoevolity and \dppmsbayes, the settings were
\begin{enumerate}
    \item $\ncomparisons = 3$
    \item $\concentration = 1.414216$, which corresponds with a prior mean of
        $\nevents = 2$ divergence events
    \item $\divtime \sim \dgamma{2}{0.05}$
    \item $\murate = 1$
    \item $\epopsize[\descendantpopindex{}] \sim \dgamma{5}{0.002}$
\end{enumerate}
For analyses with \dppmsbayes, the effective size of the ancestral population,
\epopsize[\rootpopindex], was also distributed as \dgamma{5}{0.002}, whereas
for \ecoevolity, the relative effective size of the ancestral population,
\rootrelativepopsize, was distributed as \dgamma{100}{1};
the marginal prior on \epopsize[\rootpopindex] induced by the latter is similar
to the former.
For analyses with \dppmsbayes, we assumed a Jukes-Cantor model of nucleotide
substitution, whereas for the \ecoevolity, we assumed the two-state equivalent
(i.e., $\gfreq = 0.5$).

Each method was applied to 100 data sets simulated under its own model.
Thus, there were no model violations, except for the new method, for which the
assumption of unlinked characters was violated by the 200-character loci.
For the analysis of each simulated data set with \ecoevolity, three independent
MCMC chains were run for 75,000 generations, sampling every 50th generation.
For the \dppmsbayes analyses, 500,000 samples were simulated from the joint
prior distribution, 2,000 of which were retained for the approximate posterior
sample.

\subsection{Empirical application}
Previous methods for estimating shared divergence times often over-cluster taxa
\citep{Oaks2012,Oaks2014reply} or have little information to update prior
expectations \citep{Oaks2014dpp}.
Thus, a good empirical test of the new method would be pairs of populations
that we expect diverged independently of one another.
We collected RADseq data from four pairs of populations of \spp{Gekko} lizards.
Each pair of populations inhabit two different oceanic islands in the
Philippines that were never connected during lower sea levels of glacial
periods.
Because these islands were never connected, the divergence between the
populations of each pair is necessarily due to dispersal, the timing of which
should be idiosyncratic to each pair.

We analyzed the data with and without the constant characters.
Also, there were a small number of sites that had more than two nucleotides
represented, which cannot be handled directly by our model of biallelic
data.
We explored two ways of handling these sites:
(1) excluding them, and
(2) coding the first nucleotide in the alignment as 0 (``green''), and all
other nucleotides for that site as 1 (``red'').
Thus, between including/excluding the constant sites and removing/re-coding the
polyallelic characters, we analyzed four versions of the RADseq data.

To be conservative in assessing the ability of the new method to distinguish
divergence times among the pairs, we set $\concentration = 0.44$, which places
50\% of the prior probability on one divergence event (i.e., all four pairs
sharing the same divergence).
Furthermore, to assess the sensitivity of the results to the \concentration, we
also tried $\concentration = 3.77$, which corresponds with a prior mean number
of divergence events of three.
Other settings that were shared by all analyses of the \spp{Gekko} RADseq data
include:
\begin{itemize}
    \item $\epopsize[\descendantpopindex{}] \sim \dgamma{4}{0.004}$
    \item $\rootrelativepopsize \sim \dgamma{100}{1}$
    \item $\gfreq = 0.5$
    \item $\murate = 1$ for all four pairs
\end{itemize}

The ABC methods of inferring shared divergence events are very sensitive to the
prior divergence times
\citep{Oaks2012,Hickerson2013,Oaks2014reply,Oaks2014dpp}.
To assess whether results of our new method are also sensitivity of to the
prior on divergence times, we analyzed the data sets that included constant
characters under the following priors:
\begin{enumerate}
    \item $\divtime \sim \dexponential{0.005}$
    \item $\divtime \sim \dexponential{0.01}$
    \item $\divtime \sim \dexponential{0.05}$
    \item $\divtime \sim \dexponential{0.1}$
    \item $\divtime \sim \dexponential{0.2}$
\end{enumerate}
For the two versions of the \spp{Gekko} data that lacked the constant
characters, we tried the following priors:
\begin{enumerate}
    \item $\divtime \sim \dexponential{0.01}$
    \item $\divtime \sim \dexponential{0.05}$
    \item $\divtime \sim \dexponential{0.1}$
    \item $\divtime \sim \dexponential{0.2}$
    \item $\divtime \sim \dexponential{0.5}$
\end{enumerate}

For all analyses, we ran 10 independent MCMC chains for 150,000 generations,
sampling every 100th generation.
Convergence and mixing of the chains was assessed by the potential scale
reduction factor (the square root of Equation 1.1 in Brooks and Gelman
\citeyear{Brooks1998}) and effective sample size \citep{Gong2014} of the
likelihood and all parameters, and inspected visually with the program Tracer
version 1.6
\citep{Tracer16}.


\section{Results}

\subsection{Analyses of simulated data}

\subsubsection{Validation analyses}

There were approximately 5,500 and 27,500, variable sites, on average, from the
100,000 and 500,000-character data sets, respectively
(Figures S\ref{fig:valnumberofvariablesites100k} \&
S\ref{fig:valnumberofvariablesites500k}).
However, the range of the number of variable sites was 515--21,676 
and 4,670--105,373 for 100,000 and 500,000-character data sets, respectively.
As expected, the variance in the number variable sites increases with the
variance in the distribution of the relative effective size of the root
population
(Figures S\ref{fig:valnumberofvariablesites100k} \&
S\ref{fig:valnumberofvariablesites500k}).

The MCMC chains for all analyses converged very quickly;
we conservatively removed the first 401 samples, resulting in 3300 samples from
the posterior (1100 samples from three chains) for each analysis.
To assess convergence and mixing we plotted the potential scale reduction
factor across the three independent chains and the effective sample size for
the log likelihood and divergence times
(Figures S\ref{fig:valpsrflikelihood}, S\ref{fig:valpsrfdivtimes},
S\ref{fig:valesslikelihood}, \& S\ref{fig:valessdivtimes}).
Mixing was poorer when there was more prior uncertainty in the root population
size
(Figures S\ref{fig:valesslikelihood} \& S\ref{fig:valessdivtimes}).
However, given the expected frequentist behavior for how often the true
parameter values were contained within the 95\% confidence intervals (see
below), and the weak relationship between the ESS and estimation error
(Figure~S\ref{fig:valessvserror}),
we do not expect MCMC mixing had a large effect on our simulation results under
extreme levels of uncertainty in the root population size.

Figure~\ref{fig:valdivtimes}

Figure~\ref{fig:valleafsizes}

Figure~\ref{fig:valrootsizes}

Figure~\ref{fig:valnevents}

Figure~\ref{fig:valpostprobs}

\subsubsection{Assessing effect of linkage violation}

Report the average number of variable characters per locus.

Figure~S\ref{fig:linkagenumberofvariablesites100k}

Figure~S\ref{fig:linkagenumberofvariablesites100k}

Figure~\ref{fig:linkagedivtimes100k}

Figure~\ref{fig:linkagedivtimes500k}

Figure~\ref{fig:linkagenevents100k}

Figure~\ref{fig:linkagenevents500k}

Figure~\ref{fig:linkagepostprobs}

Figure~\ref{fig:linkageleafsizes100k}

Figure~\ref{fig:linkageleafsizes500k}

Figure~\ref{fig:linkagerootsizes100k}

Figure~\ref{fig:linkagerootsizes500k}


\subsubsection{Assessing the effect of missing data}

Figure~\ref{fig:missingdivtimes}

Figure~\ref{fig:missingnevents}

Figure~S\ref{fig:missingleafsizes}

Figure~S\ref{fig:missingrootsizes}


\subsubsection{Assessing the effect of biases in character-pattern acquisition}

Figure~\ref{fig:filtereddivtimes}

Figure~\ref{fig:filterednevents}

Figure~S\ref{fig:filteredleafsizes}

Figure~S\ref{fig:filteredrootsizes}


\subsubsection{Comparison to ABC methods}

Figure~\ref{fig:bakeoffdivtimes}

Figure~\ref{fig:bakeoffnevents}

Figure~S\ref{fig:bakeoffleafsizes}

Figure~S\ref{fig:bakeoffrootsizes}


\subsection{Empirical application}

Figure~\ref{fig:gekkodivtimes}

Figure~\ref{fig:gekkosizes}

Figure~\ref{fig:gekkonevents}

Figure~S\ref{fig:gekkonopolydivtimes}

Figure~S\ref{fig:gekkonopolysizes}

Figure~S\ref{fig:gekkonopolynevents}

Figure~S\ref{fig:gekkovaronlydivtimes}

Figure~S\ref{fig:gekkovaronlysizes}

Figure~S\ref{fig:gekkovaronlynevents}

Figure~S\ref{fig:gekkonopolyvaronlydivtimes}

Figure~S\ref{fig:gekkonopolyvaronlysizes}

Figure~S\ref{fig:gekkonopolyvaronlynevents}

\section{Discussion}
